% !TeX program = lualatex

\documentclass[
ngerman,
subtask=ruled %or plain
]{tudaexercise}

\usepackage[english, main=ngerman]{babel}
\usepackage[autostyle]{csquotes}

\usepackage{amsmath,amssymb}

\usepackage{float}

\usepackage{tikz,pgfplots}

\usepackage{biblatex}
%\bibliography{DEMO-TUDaBibliography}

\newcommand{\dd}{\,\mathrm{d}}
\newcommand{\e}{\mathrm{e}}


\ConfigureHeadline{
	headline={HSI Übung 2 - Niklas Beck und Paul Hollmann}
}

\begin{document}
	
	\title[Übung Hochleistungssimulationen]{Hochleistungssimulationen}
	\subtitle{\"Ubung 2}
	\author{Niklas Beck (2582775), Paul Hollmann (2465070)}
	\term{Wintersemester 2023/24}
	%\sheetnumber{1}
	\date{Abgabe 22. Dezember 2023}
	\maketitle
	
	\hrule
	{\Large \textbf{Cannon-Iteration}}
	\hrule
	
	In dieser Übung soll das Matrix-Matrix-Produkt von quadratischen Matrizen per Cannon-Algorithmus untersucht werden.
	Für große Matrizen sind parallele Algorithmen häufig sinnvoll um die Rechenzeit zu kürzen.
	
	\begin{task}{Sequentieller Algorithmus der Cannon-Iteration}\label{task:1}
		Ein paralleles Programm starten wir erstmal wieder mit der Entwicklung eines sequentiellen.
		Als kleinen Zwischenschritt haben wir erst ohne Teilblöcke in der Matrix gearbeitet und später die Struktur der Matrix erweitert.
		
		Zuerst werden zwei Matrizen A und B gefüllt, testweise mit der Zahlenreihe von 1 bis $n \times n$.
		In dieser Übung werden wir doppelte Schleifen zur Füllung, Lesen oder Berechnen mit einer Matrix häufig sehen.
		Also hier bereits eine doppelte Initialisierungsschleife. Gleich danach auch eine einfache Testfunktion um Matrizen auf die Konsole ausgeben zu können.
		
		Ausgelagert in eine Funktion programmieren wir einen Schritt der Cannon-Iteration.
		Die Vertauschung in steigender Anzahl an Tauschvorgängen braucht eine Schleife mehr. Zum Tausch muss eine Zwischenspeicherung verwendet werden.
		
		Anschließend wird der eigentliche Cannon-Iterationsschritt gemacht. So häufig wie die Matrizen Zeilen (oder Spalten) besitzen werden die folgenden beiden Schritte gemacht:
		\begin{itemize}
			\item Berechne die Multiplikation der Elemente $A_{ij}$ und $B_{ij}$ für die Ergebnismatrix an gleicher Position.
			\item Vertausche in Matrix A alle Elemente spaltenweise nach links und in Matrix B alle Elemente zeilenweise nach oben.
		\end{itemize}
		Durch diese Vertauschungen werden alle notwendigen Elemente der Matrizen miteinander multipliziert und es ergibt sich das gewünschte Produkt.
		
		Zur Erweiterung der Berechnung für Blockmatrizen muss die Speicherung zuerst angepasst werden. Ein Zweidimensionales Array dient uns hier als Mittel. Darauf müssen die Funktionsdefinitionen und der Befehlszeilen-Output angepasst werden.
		Auch werden kleine Berechnungen mit Gesamtgröße der Matrix $n$ und Wurzel der Prozessoranzahl $p$ gebraucht.
		In der Funktion zur Cannon-Iteration müssen viele Schleifenköpfe auf die Anzahl der Durchläufe angepasst werden.
		Der größte Unterschied liegt in einer ausformulierte Matrixmultiplikation statt einer einfachen Multiplikation.
	\end{task}
	
	
	\begin{task}{Paralleler Algorithmus mit MPJ}
		Um den Cannon-Algorithmus effizient mit $p \times p$ Prozessen ausführen zu können,
		müssen die Matrixelemente der Matratzen $A$, $B$ und $C$ auf die einzelnen Prozesse aufgeteilt werden.
		Die gesamten Matrizen werden dazu in einen eindimensionalen Array gespeichert. 
		Die Indizierung für den $(x,y)$-ten Eintrag im $(i,j)$-ten Block lautet hierbei
		\begin{equation*}
			M_{xy}^{ij} = {M}_{u}^{\mathrm{ges}}~,~~\text{ wobei } u =jddp +idd + yd +x
		\end{equation*}
		in der Gesamt-Matrix.
		
		Mit der oben genannten Indizierung kann nun einfach vom Host-Prozess jede Teil-Matrix an die anderen propagiert werden,
		dazu wird \texttt{MPI.COMM\_WORLD.Scatter} benutzt um die Einträge an die lokalen Zwischenspeicher zu senden.
		Jeder Prozess verwaltet seine eigenen lokalen Daten in je zwei Einträgen für $A^{\mathrm{lkl}}$ und $B^{\mathrm{lkl}}$ und einen Eintrag für $C^{\mathrm{lkl}}$.
		
		Bei der initialen (und auch allen folgenden) Austauschoperation werden die Daten von $A^{\mathrm{lkl}}$ und $B^{\mathrm{lkl}}$ immer in das grade nicht verwendete Array empfangen und die zu senden aus dem entsprechend anderem.
		Diese Sendoperationen werden alle immer non-blocking ausgeführt, somit wird der Befehl \texttt{Isend} benutzt.
		
		!!!!!
	
	\end{task}
	
	\begin{task}{Zeitmessung}
		!!!!!
	
		
	\end{task}
	
	\begin{task}{Ausführung auf dem Lichtenberg-Hochleistungsrechner} 
		Zur Ausführung auf dem Cluster wird ein Job Script gebraucht. 
		Die beiden Größe der Matrix werden als Kommandozeilenparameter übergeben.
		Das batch Dokument vecmat.sh kann per SLURM in die Processqueue übergeben werden.
		
		!!!!!
		
		Dieses nimmt einige Einstellungen vor, lädt die notwendigen Module, baut das Programm unter Nutzung der Maven Bibliothek und führt es dann in unterschiedlichen Parameterkonfigurationen aus.
	\end{task}

	

	\begin{task} {Erwartete Ergebnisse}
		Für das Beispiel einer 6 $/times$6 Matrix auf einem Prozessorengitter von 3$/times$3 prüfen wir die Ergebnisse des parallelen Algorithmus auf dem Cluster mit der sequenziellen Berechnung.
		
		Um zu prüfen, wie viel uns die MPJ-Umsetzung als Speedup geliefert hat, messen wir verschiedene Laufzeiten.
		Vorgegeben sind n aus $(n = 250 * p * i | i=1...8)$.
		
		Tabelle mit Werten
		
		Nun wollen wir den Speed-up in Abhängigkeit der Prozessoren $p \in (1, 64)$ berechnen.
		
		versch Verteilung der Prozesse auf die verfügbaren Knoten, Proz und Kerne
	\end{task}


	\appendix
	\section{Appendix}
	

	
	
\end{document}